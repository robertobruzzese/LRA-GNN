si lancia morph.py che ha il set di landmarks e  crea il file con le coordinate dei punti dei landmark ridotti nella cartella point_reduced

lo script extract_metadata estrae i metadati e li scrive in datasets/data/MORPH/images/Train/metadata/morph_data.csv

dopo aver lanciato morph.py si dovrebbe lanciare draw_landmarks.py che legge sia i landmarks completi che quelli che sono reduced (creati da morph) e li disegna sulle immagini contenute in MORPH/images/Train/landmarked e MORPH/images/Train/landmarked_reduced

dopo dovrebbe lanciarsi segment_patches.py che segmenta in patch con all interno i keypoints
questo script crea un file con le coordinate delle patches create nella cartella patches dal nome nomeimmagine_patches.csv (√® un dizionario di keypoint patch map)

dopo si lancia graph_contsructor.py (che per√≤ non visualizza il grafo perch√® lo fa il main.py)

quindi si lancia main.py

il file batch_preprocess_faces chiama utils/preprocessing.py ed elabora la dimensione di tutte le immagini nella directore images/Train e le mette nella cartella image_preprocessed

si lancia PYTORCH_ENABLE_MPS_FALLBACK=1 python train_rl_agent.py 
PYTORCH_ENABLE_MPS_FALLBACK=1 python evaluate_rl_agent.py (dopo aver lanciato train_rl_agent.py)
PYTORCH_ENABLE_MPS_FALLBACK=1 python models/train_classifier.py (PRIMA DI LANCIARE TRAIN_RL_AGENT.PY)
---------------------------
1)per il preprocessing si lancia batches_preprocess_faces_fgnet.py oppure batch_preprocess_faces_morph.py e le immagini preprocessate normalizzate saranno messe dentro la cartellla image_preprocessed
2) si lancia datasets/morph.py oppure datasets/fgnet.py che √® lo script che genera i landmark completi e ridotti a partire dalle immagini preprocessate! cosa fa ? Per ogni immagine in images_preprocessed, estrae:
I 68 landmark facciali completi
Un sottoinsieme ridotto di landmark chiave (es. occhi, naso, bocca)
E salva due file .pts per ciascuna immagine:
In points/ ‚Üí 68 landmark
In points_reduced/ ‚Üí landmark selezionati per analisi (es. aging)
3) si lancia datasets/draw_landmarks_morph.py o draw_landmark_fgnet.py per visualizzare i landmark
questo script ha come output images/Train/landmarked/	üì∏ Immagini con 68 landmark (rossi)	Se esiste points/<nome>.pts
images/Train/landmarked_reduced/	üì∏ Immagini con landmark ridotti (blu)	Se esiste points_reduced/<nome>.pts

4) utils/segment_patches_morph.py o utils/segment_patches_fgnet.py üîç Questo script ha lo scopo di analizzare immagini faciali preprocessate, associare i keypoint facciali a delle patch regolari 6√ó6 sovrapposte all‚Äôimmagine, e salvare i risultati sia come CSV che come immagine visuale con overlay delle patch e landmark. dentro la cartella Train/images_segmented
esso carica  i keypoint (landmark ridotti) da points_dir = "datasets/data/MORPH/points_reduced" o points_dir = "datasets/data/FGNET/points_reduced"
5) dopo di che si lancia main_morph.py oppure main_fgnet.py che chiamano la versione  graph_constructor_morph.py oppure graph_constructor_morph.py per creare il grafo per ogni immagine e fa queste azioni 
Step	Cosa fa	Script  
1Ô∏è‚É£	Carica immagine + patch CSV	image_path, csv_path	‚úÖ
2Ô∏è‚É£	Costruisce grafo base + RW	construct_initial_graph	‚úÖ
3Ô∏è‚É£	Salva graph_initial.pt, graph_rw.pt		‚úÖ
4Ô∏è‚É£	Applica Latent Relation Capturer (LRC)	LatentRelationCapturer	‚úÖ
5Ô∏è‚É£	Salva 12 grafi LRC (graph_lrc_*.pt)		‚úÖ
6Ô∏è‚É£	Estrae deep feature via ResGCN	extract_deep_features	‚úÖ
7Ô∏è‚É£	Salva deep_features.pt
ode_features.pt	Embedding visivo 512D per ogni patch (nodo)
edge_features.pt	(Opzionale) Media degli embedding tra coppie connesse
graph_initial.pt	Grafo iniziale basato su similarit√†
graph_rw.pt	Grafo dopo Random Walk
graph_lrc_*.pt (12 file)	Grafi connessi via multi-head attention
deep_features.pt	Feature finali da ResGCN
‚úÖ Conclusione
Hai centrato il punto:
‚úî S√¨, il sistema genera anche gli embedding delle patch (nodi)
‚úî Sono salvati in node_features.pt nella cartella dell‚Äôimmagine

6) viene poi lanciato il classificatore python models/train_classifier.py --dataset FGNET (o MORPH)

7) adesso va lanciato train_lra_gnn.py  --dataset MORPH oppure FGNET
cos√¨ : python train_lra_gnn.py --dataset FGNET
il comando da dare su mac con gpu √® questo:
PYTORCH_ENABLE_MPS_FALLBACK=1
python train_lra_gnn.py --dataset FGNET (oppure MORPH)


8) infine viene lanciato PYTORCH_ENABLE_MPS_FALLBACK=1 python train_rl_agent.py --dataset FGNET (oppure MORPH)
 
 9) per la evaluation : PYTORCH_ENABLE_MPS_FALLBACK=1 python evaluate_rl_agent.py --dataset FGNET (oopure MORPH)
